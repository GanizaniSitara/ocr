#!/usr/bin/env python3
"""
OpenAI Vision API test script - compare against Tesseract OCR.
"""

import base64
import json
from pathlib import Path
import pytesseract
from PIL import Image
import openai
import os
import sys


def setup_openai():
    """Setup OpenAI client with API key."""
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ OPENAI_API_KEY environment variable not set")
        print("Set it with: export OPENAI_API_KEY='your-api-key-here'")
        print("Or: set OPENAI_API_KEY=your-api-key-here  (Windows)")
        return None
    
    return openai.OpenAI(api_key=api_key)


def encode_image(image_path):
    """Encode image to base64 for OpenAI API."""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')


def test_openai_vision(client, image_path):
    """Test OpenAI GPT-4 Vision on the image."""
    print("ðŸ¤– OPENAI GPT-4 VISION RESULTS:")
    print("-" * 50)
    
    try:
        # Encode image
        base64_image = encode_image(image_path)
        
        # Create the prompt
        prompt = """Extract ALL visible text from this image. This appears to be a magazine cover.

Please extract:
1. Magazine title/masthead
2. Issue number and date information
3. Headlines and subheadings
4. Price information
5. Any speech bubbles or captions
6. Any other visible text

Format your response as a JSON object with this structure:
{
  "masthead": "main magazine title",
  "issue_info": "issue number and date",
  "price": "price if visible",
  "main_headline": "primary headline",
  "speech_bubbles": ["bubble 1 text", "bubble 2 text"],
  "other_text": ["any other text found"],
  "confidence": "high/medium/low"
}

Be thorough and extract even text on colored backgrounds or stylized fonts."""

        # Make API call
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{base64_image}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            max_tokens=1000
        )
        
        # Extract and parse response
        response_text = response.choices[0].message.content
        print("Raw response:")
        print(response_text)
        
        # Try to extract JSON if present
        try:
            if '```json' in response_text:
                json_start = response_text.find('```json') + 7
                json_end = response_text.find('```', json_start)
                json_text = response_text[json_start:json_end].strip()
            elif '{' in response_text and '}' in response_text:
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                json_text = response_text[json_start:json_end]
            else:
                json_text = response_text
            
            parsed_result = json.loads(json_text)
            
            print("\nðŸ“‹ STRUCTURED EXTRACTION:")
            print("-" * 30)
            for key, value in parsed_result.items():
                if isinstance(value, list):
                    print(f"{key.upper()}: {', '.join(value) if value else 'None found'}")
                else:
                    print(f"{key.upper()}: {value}")
                    
            return parsed_result
            
        except json.JSONDecodeError:
            print("\nâš ï¸  Could not parse as JSON, but got text response")
            return {"raw_response": response_text}
            
    except Exception as e:
        print(f"âŒ Error calling OpenAI Vision API: {e}")
        return None


def test_tesseract_comparison(image_path):
    """Test Tesseract for comparison."""
    print("\nðŸ”§ TESSERACT COMPARISON:")
    print("-" * 50)
    
    try:
        image = Image.open(image_path)
        
        # Test our best configurations
        configs = [
            ("PSM 11 Sparse", "--psm 11 --oem 3"),
            ("PSM 7 Single Line", "--psm 7 --oem 3"),
            ("PSM 8 Single Word", "--psm 8 --oem 3"),
        ]
        
        tesseract_results = {}
        all_text_combined = ""
        
        for name, config in configs:
            try:
                text = pytesseract.image_to_string(image, config=config).strip()
                tesseract_results[name] = text
                all_text_combined += " " + text
                if text:
                    print(f"{name}: {repr(text[:80])}...")
                else:
                    print(f"{name}: No text extracted")
            except Exception as e:
                print(f"{name}: Error - {e}")
        
        # Check for key magazine terms
        key_terms = ['PRIVATE', 'EYE', 'ANDREW', 'DENIES', 'BEING', 'CHINESE', 'SPY', '1642']
        found_terms = [term for term in key_terms if term in all_text_combined.upper()]
        missing_terms = [term for term in key_terms if term not in all_text_combined.upper()]
        
        print(f"\nâœ… Tesseract found: {found_terms}")
        print(f"âŒ Tesseract missed: {missing_terms}")
        
        return tesseract_results
        
    except Exception as e:
        print(f"âŒ Tesseract error: {e}")
        return {}


def compare_results(openai_result, tesseract_results):
    """Compare OpenAI vs Tesseract results."""
    print(f"\n{'='*60}")
    print("ðŸ“Š COMPARISON ANALYSIS:")
    print(f"{'='*60}")
    
    if openai_result and isinstance(openai_result, dict):
        print("\nðŸ† WINNER: OpenAI GPT-4 Vision")
        print("Reasons:")
        
        # Check what OpenAI found that Tesseract missed
        if 'masthead' in openai_result and openai_result['masthead']:
            print(f"âœ… Found masthead: {openai_result['masthead']}")
        
        if 'main_headline' in openai_result and openai_result['main_headline']:
            print(f"âœ… Found headline: {openai_result['main_headline']}")
            
        if 'issue_info' in openai_result and openai_result['issue_info']:
            print(f"âœ… Found issue info: {openai_result['issue_info']}")
            
        if 'speech_bubbles' in openai_result and openai_result['speech_bubbles']:
            print(f"âœ… Found speech bubbles: {len(openai_result['speech_bubbles'])} detected")
        
        # Check confidence
        confidence = openai_result.get('confidence', 'unknown')
        print(f"âœ… Confidence level: {confidence}")
        
        print(f"\nðŸ’¡ OpenAI Vision successfully extracted structured, meaningful text")
        print(f"   while Tesseract struggled with the magazine layout and colored backgrounds.")
        
    else:
        print("âš ï¸  Could not fully compare results")
    
    print(f"\nðŸŽ¯ RECOMMENDATION FOR YOUR USE CASES:")
    print(f"   ðŸ“° Magazine Archiving: Use OpenAI Vision API")
    print(f"   ðŸ’» Controls Testing: Start with Vision API, fallback to Tesseract for simple UI")
    print(f"   ðŸ’° Cost: ~$0.01-0.02 per image vs free Tesseract (but much better accuracy)")


def main():
    # Get image path
    if len(sys.argv) > 1:
        image_path = sys.argv[1]
    else:
        # Auto-find first PNG
        png_files = list(Path(".").glob("Scan*.png"))
        if not png_files:
            print("No PNG files found. Usage: python openai_vision_test.py [image_path]")
            return
        image_path = str(png_files[0])
    
    if not Path(image_path).exists():
        print(f"Image not found: {image_path}")
        return
    
    print(f"Testing OCR approaches on: {Path(image_path).name}")
    print(f"Image size: {Image.open(image_path).size}")
    
    # Setup OpenAI
    client = setup_openai()
    if not client:
        return
    
    # Test OpenAI Vision
    openai_result = test_openai_vision(client, image_path)
    
    # Test Tesseract for comparison
    tesseract_results = test_tesseract_comparison(image_path)
    
    # Compare results
    compare_results(openai_result, tesseract_results)
    
    # Save results
    results = {
        'image': str(image_path),
        'openai_vision': openai_result,
        'tesseract': tesseract_results,
        'timestamp': str(Path().cwd())
    }
    
    output_file = Path("vision_test_results.json")
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nðŸ’¾ Results saved to: {output_file}")


if __name__ == "__main__":
    main()